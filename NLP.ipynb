{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\spyro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\spyro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\spyro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\spyro\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import unicodecsv                               # csv reader\n",
    "import re                                       # regular expressions\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify import SklearnClassifier\n",
    "import csv\n",
    "import pandas\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "# To do preprocessing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support # to report on precision and recall\n",
    "import numpy as np # To compute the average results\n",
    "\n",
    "from random import shuffle # To shuffle the dataset\n",
    "\n",
    "\n",
    "# To use feature selection in the Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the function for preprocessing the data, was taken from lab2\n",
    "\n",
    "def preProcess(text):\n",
    "    # should return a list of tokens\n",
    "    \n",
    "    # word tokenisation, including punctuation removal\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    # lowercasing\n",
    "    tokens = [t.lower() for t in tokens]\n",
    "\n",
    "    # stopword removal- benefits are it removes rare words, though bad for bigram relations\n",
    "    if False:\n",
    "        stop = set(stopwords.words('english'))\n",
    "        tokens = [t for t in tokens if t not in stop]\n",
    "    \n",
    "    # lemmatisation\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    tokens = [lemmatiser.lemmatize(t) for t in tokens]\n",
    "    tokens = [t for t in tokens if t] # ensure no empty space\n",
    "    \n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  character  gender\n",
      "0                                       Someone had fun.       SEAN    male\n",
      "1      It's no problem, honestly. Go on, go and open ...    SHIRLEY  female\n",
      "2      Last night was better than ever. What's all th...        MAX    male\n",
      "3          Have you checked the answerphone?  Any calls?        IAN    male\n",
      "4                                        Oscar's asleep.        MAX    male\n",
      "5                             Dead Arm? What's Dead Arm?      MINTY    male\n",
      "6                                                 Rox...     RONNIE  female\n",
      "7      Oh no, I wouldn't do that. Here's the menu. Sh...        IAN    male\n",
      "8              I think I've got someone in line already.     RONNIE  female\n",
      "9                       Like drinking yourself to death?       SEAN    male\n",
      "10     You trying to kiss me doesn't change anything....     STACEY  female\n",
      "11     Well as long as the Queen likes it. That's the...        IAN    male\n",
      "12     You know I've been thinking.    You might be b...       JANE  female\n",
      "13     I ain't the one who's been telling porkies. Wh...       PHIL    male\n",
      "15     He's had such a horrible time. I wouldn't...St...      CLARE  female\n",
      "16     It's not about the money, Max.  It never was. ...      TANYA  female\n",
      "17     You must have to go to some unusual houses in ...        IAN    male\n",
      "18     Yeah. If she'd had been on the boat to begin w...    SHIRLEY  female\n",
      "19                              I was worried about you.    HEATHER  female\n",
      "20     Alright. Is that why you haven't signed those ...      TANYA  female\n",
      "21     But I'm here now I thought near death experien...    HEATHER  female\n",
      "22     So you take off again, eh? What a surprise. Yo...      GARRY    male\n",
      "23     No no, that's the development, they've offered...    BRADLEY    male\n",
      "24                           How the hell should I know?    SHIRLEY  female\n",
      "25                                              And you?       SEAN    male\n",
      "26           Remember we're seeing the accountant later.       JANE  female\n",
      "27     I would. You turn up with food for twenty and ...  CHRISTIAN    male\n",
      "28                                          Yeah course.      GARRY    male\n",
      "29     You'll have hours to think about what you did ...      TANYA  female\n",
      "30          And nearly a whole year till next Christmas.     RONNIE  female\n",
      "...                                                  ...        ...     ...\n",
      "10083  All I need to hear is âno Jack, I didn't do ...       JACK    male\n",
      "10084  Well, 'cause I love ya... It makes me sick to ...        MAX    male\n",
      "10085  Yeah... Anyway, give Grandad a big hug for me....    BRADLEY    male\n",
      "10086                                       What's that?        IAN    male\n",
      "10087     Paying out for a teenager's party - no chance.       JANE  female\n",
      "10088  Well I hate to disappoint you, but I like a bl...    SHIRLEY  female\n",
      "10089                                      Yeah why not?        IAN    male\n",
      "10090  And it's not bonding if you then withdraw it. ...       JANE  female\n",
      "10091     Hello Garry. Minty.  About this wedding Minty.    HEATHER  female\n",
      "10092  He's my godson.  Look Ian, sit down. I'll make...       JANE  female\n",
      "10093            Well, here's to a long and happy union.       JANE  female\n",
      "10094                                             Hello.     STACEY  female\n",
      "10095                                   How much longer?     STEVEN    male\n",
      "10096                                        Oh shut up.       JANE  female\n",
      "10097                                         Well then.        IAN    male\n",
      "10098                                    Oh thanks, um-?      TANYA  female\n",
      "10099                      Er, no, I don't think so, no.       JANE  female\n",
      "10100  Quick enoughfor you?  Give me one goodreason w...      MINTY    male\n",
      "10101                       Er, I think so, I'll get it.      TANYA  female\n",
      "10102  There they are.  Come on up.  Told you there w...    HEATHER  female\n",
      "10103                Have you got our bacon rolls ready?     STACEY  female\n",
      "10104  It's about ambition.  What do you want from yo...        IAN    male\n",
      "10105  And telling them what?  I ain't done nothing, ...       PHIL    male\n",
      "10106  If I don't over-charge the City lot they won't...     RONNIE  female\n",
      "10107  This is serious Christian. I'm just as angry a...       JANE  female\n",
      "10108  What's going on Gal? What's going on? I don't ...      MINTY    male\n",
      "10109              Am I mad?  Have I completely lost it?      TANYA  female\n",
      "10110                                       You're late.       JACK    male\n",
      "10111                                Ask your psycho Ex.       ROXY  female\n",
      "10112  She's got an evening shift but I don't want to...       PHIL    male\n",
      "\n",
      "[10071 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#Loading the training set and droping null columns\n",
    "Corpus = pd.read_csv(r'training.csv',encoding='latin-1',names=['text', 'character', 'gender'])\n",
    "Corpus = Corpus.dropna()\n",
    "print(Corpus)\n",
    "#Loading the test set and droping null columns\n",
    "Test = pd.read_csv(r'test.csv',encoding='latin-1',names=['text', 'character', 'gender'])\n",
    "Test = Test.dropna()\n",
    "\n",
    "#preprocessing the data with the preProcess function\n",
    "for index, line in Corpus.iterrows():\n",
    "    Corpus['text'][index] = preProcess(line.text)\n",
    "\n",
    "\n",
    "#preprocessing the data with the preProcess function\n",
    "for index, line in Test.iterrows():\n",
    "    Test['text'][index] = preProcess(line.text)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a unigram on the training set\n",
    "unigram = Counter()\n",
    "for line in Corpus['text']:\n",
    "    for w in line:\n",
    "        unigram[w]+=1\n",
    "\n",
    "#print(len(unigram),unigram)\n",
    "\n",
    "\n",
    "#create a bigram\n",
    "bigram = []\n",
    "for tokens in Corpus['text']:\n",
    "    for i in range(len(tokens)-1):\n",
    "        bigram.append(tokens[i:i+2])\n",
    "\n",
    "#postag\n",
    "#a=[]\n",
    "#b=[]\n",
    "#for tokens in Corpus['text']:\n",
    "#    tag = nltk.pos_tag(tokens)\n",
    "#    b.append(tag)\n",
    "    #print(tag)\n",
    "#    grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "#    cp  =nltk.RegexpParser(grammar)\n",
    "#    result = cp.parse(tag)\n",
    "#    a.append(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 500)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq\n",
    "#we are using as feautures the 500 most common/frequent words from our vocabulary.\n",
    "most_freq = heapq.nlargest(500, unigram, key=unigram.get)\n",
    "\n",
    "#create bag of words for the Corpus data.\n",
    "sentence_vectors = []\n",
    "for text in Corpus['text']:\n",
    "    i=len(text)\n",
    "    sent_vec = []\n",
    "    for token in most_freq:\n",
    "        if token in text:\n",
    "            sent_vec.append(1)\n",
    "            #print(token,text)\n",
    "        else:\n",
    "            sent_vec.append(0)\n",
    "    #sent_vec.append(i)\n",
    "    #if you want to include in the classification the length of the sentance as an extra feature uncomment the above line.\n",
    "    sentence_vectors.append(sent_vec)\n",
    "\n",
    "   # print(sent_vec)\n",
    "sentence_vectors = np.asarray(sentence_vectors)\n",
    "#print(sentence_vectors)\n",
    "\n",
    "#create bag of words for the Test data.\n",
    "sentence_vectors_test = []\n",
    "for text in Test['text']:\n",
    "    e=len(text)\n",
    "    sent_vec_test = []\n",
    "    for token in most_freq:\n",
    "        if token in text:\n",
    "            sent_vec_test.append(1)\n",
    "            #print(token,text)\n",
    "        else:\n",
    "            sent_vec_test.append(0)\n",
    "    #sent_vec_test.append(e)\n",
    "    # #if you want to include in the classification the length of the sentance as an extra feature uncomment the above line.\n",
    "    sentence_vectors_test.append(sent_vec_test)\n",
    "\n",
    "sentence_vectors_test = np.asarray(sentence_vectors_test)\n",
    "sentence_vectors_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10071, 500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IDF values\n",
    "word_idf_values = {}\n",
    "for token in most_freq:\n",
    "    doc = 0\n",
    "    for text in Corpus['text']:\n",
    "        if token in text:\n",
    "            doc += 1\n",
    "    word_idf_values[token] = np.log(len(Corpus['text'])/(1 + doc))\n",
    "\n",
    "#create the TF dictionary for each word    \n",
    "word_tf_values = {}\n",
    "for token in most_freq:\n",
    "    sent_tf_vector = []\n",
    "    for document in Corpus['text']:\n",
    "        doc_freq = 0\n",
    "        for word in document:\n",
    "            if token == word:\n",
    "                  doc_freq += 1\n",
    "        if len(document)==0:\n",
    "            word_tf=0\n",
    "        else:\n",
    "            word_tf = doc_freq/len(document)\n",
    "        sent_tf_vector.append(word_tf)\n",
    "    word_tf_values[token] = sent_tf_vector\n",
    "    \n",
    "#multiply IDF values with TF values    \n",
    "tfidf_values = []\n",
    "for token in word_tf_values.keys():\n",
    "    tfidf_sentences = []\n",
    "    for tf_sentence in word_tf_values[token]:\n",
    "        tf_idf_score = tf_sentence * word_idf_values[token]\n",
    "        tfidf_sentences.append(tf_idf_score)\n",
    "    tfidf_values.append(tfidf_sentences)\n",
    "\n",
    "tf_idf_model = np.asarray(tfidf_values)\n",
    "tf_idf = tf_idf_model.transpose()\n",
    "tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the TF dictionary for each word for test  \n",
    "word_tf_values = {}\n",
    "for token in most_freq:\n",
    "    sent_tf_vector = []\n",
    "    for document in Test['text']:\n",
    "        doc_freq = 0\n",
    "        for word in document:\n",
    "            if token == word:\n",
    "                  doc_freq += 1\n",
    "        if len(document)==0:\n",
    "            word_tf=0\n",
    "        else:\n",
    "            word_tf = doc_freq/len(document)\n",
    "        sent_tf_vector.append(word_tf)\n",
    "    word_tf_values[token] = sent_tf_vector\n",
    "    \n",
    "#multiply IDF values with TF values    \n",
    "tfidf_values = []\n",
    "for token in word_tf_values.keys():\n",
    "    tfidf_sentences = []\n",
    "    for tf_sentence in word_tf_values[token]:\n",
    "        tf_idf_score = tf_sentence * word_idf_values[token]\n",
    "        tfidf_sentences.append(tf_idf_score)\n",
    "    tfidf_values.append(tfidf_sentences)\n",
    "\n",
    "tf_idf_model_test = np.asarray(tfidf_values)\n",
    "tf_idf_test = tf_idf_model_test.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the training data to train and heldout with 70& and 30& respectively for the crossvalidation\n",
    "Train_X, Heldout_X, Train_Y, Heldout_Y = model_selection.train_test_split(sentence_vectors,Corpus['gender'],test_size=0.3)\n",
    "#By changing the X from sentence_vectors to tf_idf you will use as features the tf_idf method and not the bag of words\n",
    "#If you want to classify on the character unocomment the below and comment the above\n",
    "#Train_X, Heldout_X, Train_Y, Heldout_Y = model_selection.train_test_split(sentence_vectors,Corpus['character'],test_size=0.3)\n",
    "\n",
    "Test_X = sentence_vectors_test # change to tf_idf_test to use as features the tf_idf method and not the bag of words\n",
    "Test_Y = Test['gender']\n",
    "FULL_X = sentence_vectors # change to tf_idf to use as features the tf_idf method and not the bag of words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the label\n",
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "Heldout_Y = Encoder.fit_transform(Heldout_Y)\n",
    "Test_Y = Encoder.fit_transform(Test_Y)\n",
    "FULL_Y = Encoder.fit_transform(Corpus['gender'])\n",
    "#FULL_Y = Encoder.fit_transform(Corpus['character']) if you want to classify on the character unocomment this and comment the line above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score\n",
    "\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(FULL_X,FULL_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  59.017857142857146\n",
      "SVM Recall Score ->  59.017857142857146\n",
      "SVM Precision Score ->  59.09865946378551\n",
      "SVM F1 Score ->  58.978985603617964\n"
     ]
    }
   ],
   "source": [
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X)\n",
    "\n",
    "# Use accuracy_score function,recall_score,precision_score,f1_score to get the accuracy,recall,precision and f1 score\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)\n",
    "print(\"SVM Recall Score -> \",recall_score(predictions_SVM, Test_Y,average='weighted')*100)\n",
    "print(\"SVM Precision Score -> \",precision_score(predictions_SVM, Test_Y,average='weighted')*100)\n",
    "print(\"SVM F1 Score -> \",f1_score(predictions_SVM, Test_Y,average='weighted')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spyro\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5218254  0.54220457 0.53326713]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(SVM, Heldout_X,Heldout_Y)\n",
    "print(scores)\n",
    "\n",
    "#the above is the crossvalidation function to check if our model is overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the training dataset on the NB classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(FULL_X,FULL_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55257937 0.54716981 0.55412115]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spyro\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(Naive, Heldout_X,Heldout_Y)\n",
    "print(scores)\n",
    "\n",
    "#the above is the crossvalidation function to check if our model is overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  57.67857142857142\n",
      "Naive Bayes Recall Score ->  57.67857142857142\n",
      "Naive Bayes Precision Score ->  57.656962785114054\n",
      "Naive Bayes F1 Score ->  57.64126131589502\n"
     ]
    }
   ],
   "source": [
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(Test_X)\n",
    "\n",
    "# Use accuracy_score function,recall_score,precision_score,f1_score to get the accuracy,recall,precision and f1 score\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)\n",
    "print(\"Naive Bayes Recall Score -> \",recall_score(predictions_NB, Test_Y,average='weighted')*100)\n",
    "print(\"Naive Bayes Precision Score -> \",precision_score(predictions_NB, Test_Y,average='weighted')*100)\n",
    "print(\"Naive Bayes F1 Score -> \",f1_score(predictions_NB, Test_Y,average='weighted')*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spyro\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy Score ->  58.392857142857146\n",
      "Logistic Regression Recall Score ->  58.392857142857146\n",
      "Logistic Regression Precision Score ->  58.78241296518608\n",
      "Logistic Regression F1 Score ->  58.38410042584361\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "logistic_regression= LogisticRegression()\n",
    "logistic_regression.fit(FULL_X,FULL_Y)\n",
    "y_pred=logistic_regression.predict(Test_X)\n",
    "\n",
    "# Use accuracy_score function,recall_score,precision_score,f1_score to get the accuracy,recall,precision and f1 score\n",
    "print(\"Logistic Regression Accuracy Score -> \",accuracy_score(y_pred, Test_Y)*100)\n",
    "print(\"Logistic Regression Recall Score -> \",recall_score(y_pred, Test_Y,average='weighted')*100)\n",
    "print(\"Logistic Regression Precision Score -> \",precision_score(y_pred, Test_Y,average='weighted')*100)\n",
    "print(\"Logistic Regression F1 Score -> \",f1_score(y_pred, Test_Y,average='weighted')*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
